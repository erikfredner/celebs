{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which names tend to co-occur within the same document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import re\n",
    "from collections import Counter\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA = '/oak/stanford/groups/malgeehe/celebs/chicago_results/chicago_names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = [os.path.join(DATA,x) for x in os.listdir(DATA) if x.endswith('.tsv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's read in everything, and then start with all of the documents that have > 1 name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_tsv(tsv):\n",
    "    df = pd.read_csv(tsv, sep = '\\t')\n",
    "    df.columns = ['path', 'name']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.610511064529419\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with Pool() as p:\n",
    "    L = p.map(load_tsv, files)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = None # free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find docs with more than one name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = df.groupby('path').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = g[g['name'] > 1].index # docs with multiple people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of these, which are in the relevant time period since we have too many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta = pd.read_csv('/oak/stanford/groups/malgeehe/celebs/chicago_results/chicago_1919-1939_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_period = [os.path.split(x)[1] for x in meta['fullpath']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidates = [os.path.split(x)[1].split('.xml')[0] for x in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix the chunks\n",
    "candidates = [x.split('_chunk')[0] for x in candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CD_20151209220246_00001_491877180.txt'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidates) == len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CT_20170929192812_00001_181362810.txt',\n",
       " 'CD_20151209220246_00001_491877180.txt')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match\n",
    "in_period[0], candidates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_period_multiple_names = list(set(in_period) & set(candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440078"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(in_period_multiple_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_pattern = re.compile(r'C[A-Z]{1}_[0-9]{14}_[0-9]{5}_[0-9]{9}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_txt(path):\n",
    "    return re.search(word_pattern, path).group() #tuple: (path, re.search(word_pattern, x).group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.642592668533325\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df['txt'] = [extract_txt(x) for x in df['path']] # is there a way to use a generator to feed this?\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, filter `df` for elements in the `txt` column that `isin` `in_period_multiple_names`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset = df[df['txt'].isin(in_period_multiple_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4625679, 440078)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.shape[0], len(in_period_multiple_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>name</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/scratch/groups/malgeehe/celebs/chicago_corenl...</td>\n",
       "      <td>George Mem</td>\n",
       "      <td>CD_20151209222115_00011_492423658.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/scratch/groups/malgeehe/celebs/chicago_corenl...</td>\n",
       "      <td>Timmy Eritt</td>\n",
       "      <td>CD_20151209222115_00011_492423658.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/scratch/groups/malgeehe/celebs/chicago_corenl...</td>\n",
       "      <td>Jack Blackburn</td>\n",
       "      <td>CD_20151209222115_00011_492423658.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/scratch/groups/malgeehe/celebs/chicago_corenl...</td>\n",
       "      <td>Mike Twin Sul</td>\n",
       "      <td>CD_20151209222115_00011_492423658.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/scratch/groups/malgeehe/celebs/chicago_corenl...</td>\n",
       "      <td>Joe Was Sure ``</td>\n",
       "      <td>CD_20151209222115_00011_492423658.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path             name  \\\n",
       "8   /scratch/groups/malgeehe/celebs/chicago_corenl...       George Mem   \n",
       "9   /scratch/groups/malgeehe/celebs/chicago_corenl...      Timmy Eritt   \n",
       "10  /scratch/groups/malgeehe/celebs/chicago_corenl...   Jack Blackburn   \n",
       "11  /scratch/groups/malgeehe/celebs/chicago_corenl...    Mike Twin Sul   \n",
       "12  /scratch/groups/malgeehe/celebs/chicago_corenl...  Joe Was Sure ``   \n",
       "\n",
       "                                      txt  \n",
       "8   CD_20151209222115_00011_492423658.txt  \n",
       "9   CD_20151209222115_00011_492423658.txt  \n",
       "10  CD_20151209222115_00011_492423658.txt  \n",
       "11  CD_20151209222115_00011_492423658.txt  \n",
       "12  CD_20151209222115_00011_492423658.txt  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, and the goal here is to create tuples containing every possible combination of names that appear in the *same* article, and get the total frequencies with which a given pair appears.\n",
    "\n",
    "Order doesn't matter, so maybe create a tuple like this:\n",
    "\n",
    "`({name_a, name_b}, 0000)`\n",
    "\n",
    "Where index `[1]` is a numeric ID for the tuple. (Unless maybe it's just faster to use a `Counter` of sets?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# counter of sets\n",
    "articles = subset['txt'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way faster if we sort the df and chop for specific rows in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_sort = subset.sort_values('txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = sub_sort.groupby('txt').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['txt', 'path', 'name'], dtype='object')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = g['path'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe there would be a way to do this with a generator? Not sure since we need to sum the names in the end.\n",
    "\n",
    "Another way would be to update the Counter to keep the list size down, and trash the unaggregated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pairs(rows):\n",
    "    START = 0\n",
    "    N = len(rows)\n",
    "    C = Counter()\n",
    "    \n",
    "    for i,row in enumerate(rows):\n",
    "        candidates = list(subset[START:START + row]['name'])\n",
    "        L = extend([frozenset(x) for x in itertools.combinations(candidates, r = 2)])\n",
    "        START += row\n",
    "        \n",
    "        # update Counter\n",
    "        C += L\n",
    "        L = None\n",
    "        \n",
    "        # progress\n",
    "        pct = round(i/N, 2)*100\n",
    "        if pct % 1 == 0:\n",
    "            print('\\r{}%'.format(pct), end = '')\n",
    "        \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1d7cea781ada>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rows' is not defined"
     ]
    }
   ],
   "source": [
    "data = get_pairs(rows[:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And counting the pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_freqs = Counter(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop everything with freq < 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
