{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which names tend to co-occur within the same document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import re\n",
    "from collections import Counter\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA = '/oak/stanford/groups/malgeehe/celebs/chicago_results/chicago_names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = [os.path.join(DATA,x) for x in os.listdir(DATA) if x.endswith('.tsv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's read in everything, and then start with all of the documents that have > 1 name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_tsv(tsv):\n",
    "    df = pd.read_csv(tsv, sep = '\\t')\n",
    "    df.columns = ['path', 'name']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.032985210418701\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with Pool() as p:\n",
    "    L = p.map(load_tsv, files)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = None # free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find docs with more than one name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = df.groupby('path').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = g[g['name'] > 1].index # docs with multiple people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of these, which are in the relevant time period since we have too many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta = pd.read_csv('/oak/stanford/groups/malgeehe/celebs/chicago_results/chicago_1919-1939_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_period = [os.path.split(x)[1] for x in meta['fullpath']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidates = [os.path.split(x)[1].split('.xml')[0] for x in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix the chunks\n",
    "candidates = [x.split('_chunk')[0] for x in candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CD_20151209220246_00001_491877180.txt'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidates) == len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CT_20170929192812_00001_181362810.txt',\n",
       " 'CD_20151209220246_00001_491877180.txt')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match\n",
    "in_period[0], candidates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_period_multiple_names = list(set(in_period) & set(candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440078"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(in_period_multiple_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_pattern = re.compile(r'C[A-Z]{1}_[0-9]{14}_[0-9]{5}_[0-9]{9}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_txt(path):\n",
    "    return re.search(word_pattern, path).group() #tuple: (path, re.search(word_pattern, x).group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.00756359100342\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df['txt'] = [extract_txt(x) for x in df['path']] # is there a way to use a generator to feed this?\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, filter `df` for elements in the `txt` column that `isin` `in_period_multiple_names`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset = df[df['txt'].isin(in_period_multiple_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4625679, 440078)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.shape[0], len(in_period_multiple_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>name</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/scratch/groups/malgeehe/celebs/chicago_corenl...</td>\n",
       "      <td>George Mem</td>\n",
       "      <td>CD_20151209222115_00011_492423658.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/scratch/groups/malgeehe/celebs/chicago_corenl...</td>\n",
       "      <td>Timmy Eritt</td>\n",
       "      <td>CD_20151209222115_00011_492423658.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/scratch/groups/malgeehe/celebs/chicago_corenl...</td>\n",
       "      <td>Jack Blackburn</td>\n",
       "      <td>CD_20151209222115_00011_492423658.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/scratch/groups/malgeehe/celebs/chicago_corenl...</td>\n",
       "      <td>Mike Twin Sul</td>\n",
       "      <td>CD_20151209222115_00011_492423658.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/scratch/groups/malgeehe/celebs/chicago_corenl...</td>\n",
       "      <td>Joe Was Sure ``</td>\n",
       "      <td>CD_20151209222115_00011_492423658.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path             name  \\\n",
       "8   /scratch/groups/malgeehe/celebs/chicago_corenl...       George Mem   \n",
       "9   /scratch/groups/malgeehe/celebs/chicago_corenl...      Timmy Eritt   \n",
       "10  /scratch/groups/malgeehe/celebs/chicago_corenl...   Jack Blackburn   \n",
       "11  /scratch/groups/malgeehe/celebs/chicago_corenl...    Mike Twin Sul   \n",
       "12  /scratch/groups/malgeehe/celebs/chicago_corenl...  Joe Was Sure ``   \n",
       "\n",
       "                                      txt  \n",
       "8   CD_20151209222115_00011_492423658.txt  \n",
       "9   CD_20151209222115_00011_492423658.txt  \n",
       "10  CD_20151209222115_00011_492423658.txt  \n",
       "11  CD_20151209222115_00011_492423658.txt  \n",
       "12  CD_20151209222115_00011_492423658.txt  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in case below crashes\n",
    "subset.to_csv('/home/users/fredner/workspace/df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import\n",
    "subset = pd.read_csv('/home/users/fredner/workspace/df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# counter of sets\n",
    "articles = subset['txt'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way faster if we sort the df and chop for specific rows in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset = subset.sort_values('txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = subset.groupby('txt').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['txt', 'Unnamed: 0', 'path', 'name'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = g['path'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `group` should be a tuple with the following elements:\n",
    "\n",
    "- min row to slice from\n",
    "- max row to slice DF to\n",
    "\n",
    "The row relationships need to be recalculated for each `df` copy because the slices are by arbitrary size, and might interrupt a continuous section of name appearances.\n",
    "\n",
    "Actually, that's a problem for co-occurrence. And that's why the original version was done by row groupings. Got it.\n",
    "\n",
    "...\n",
    "\n",
    "- Current min (previous max)\n",
    "- Max (sum of rows to be processed)\n",
    "- Rows to be processed (slice of overall rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_groups(rows):\n",
    "    L = list(range(0, len(rows), round(len(rows) * 0.001)))\n",
    "    from_ = 0\n",
    "    to_ = 0\n",
    "    groups = []\n",
    "\n",
    "    for i, x in enumerate(L):\n",
    "        try:\n",
    "            group_rows = rows[x:L[i+1]]\n",
    "            to_ += sum(group_rows)\n",
    "            groups.append((group_rows, from_, to_))\n",
    "            from_ += sum(group_rows) # start the next loop where the previous one ended\n",
    "        except IndexError: # final loop\n",
    "            group_rows = rows[x:]\n",
    "            to_ += sum(group_rows)\n",
    "            groups.append((group_rows, from_, to_))\n",
    "        \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = make_groups(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pairs_group(group):\n",
    "    rows = group[0]\n",
    "    from_ = group[1]\n",
    "    to_ = group[2] # actually unnecessary\n",
    "#    df = subset[from_:to_].copy() # also unnecessary\n",
    "    C = Counter()\n",
    "    \n",
    "    for i,row in enumerate(rows):\n",
    "        candidates = list(subset[from_:from_ + row]['name'])\n",
    "        L = Counter([frozenset(x) for x in itertools.combinations(candidates, r = 2)])\n",
    "        from_ += row\n",
    "        \n",
    "        # update Counter\n",
    "        C += L\n",
    "        L = None\n",
    "        \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "with Pool() as p:\n",
    "    data = p.map(get_pairs_group, groups)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(data) # should be 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge results\n",
    "C = Counter()\n",
    "for x in data:\n",
    "    C += x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame(C, index = [0]).T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.columns = ['pair', 'co-occurrences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.sort_values('co-occurrences', ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And counting the pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_freqs = Counter(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop everything with freq < 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Notes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
