{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which names tend to co-occur within the same document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import re\n",
    "from collections import Counter\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA = '/oak/stanford/groups/malgeehe/celebs/chicago_results/chicago_names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = [os.path.join(DATA,x) for x in os.listdir(DATA) if x.endswith('.tsv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's read in everything, and then start with all of the documents that have > 1 name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_tsv(tsv):\n",
    "    df = pd.read_csv(tsv, sep = '\\t')\n",
    "    df.columns = ['path', 'name']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.032985210418701\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with Pool() as p:\n",
    "    L = p.map(load_tsv, files)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = None # free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find docs with more than one name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = df.groupby('path').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = g[g['name'] > 1].index # docs with multiple people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of these, which are in the relevant time period since we have too many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta = pd.read_csv('/oak/stanford/groups/malgeehe/celebs/chicago_results/chicago_1919-1939_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_period = [os.path.split(x)[1] for x in meta['fullpath']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidates = [os.path.split(x)[1].split('.xml')[0] for x in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix the chunks\n",
    "candidates = [x.split('_chunk')[0] for x in candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CD_20151209220246_00001_491877180.txt'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidates) == len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CT_20170929192812_00001_181362810.txt',\n",
       " 'CD_20151209220246_00001_491877180.txt')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match\n",
    "in_period[0], candidates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_period_multiple_names = list(set(in_period) & set(candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440078"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(in_period_multiple_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_pattern = re.compile(r'C[A-Z]{1}_[0-9]{14}_[0-9]{5}_[0-9]{9}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_txt(path):\n",
    "    return re.search(word_pattern, path).group() #tuple: (path, re.search(word_pattern, x).group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.00756359100342\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df['txt'] = [extract_txt(x) for x in df['path']] # is there a way to use a generator to feed this?\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, filter `df` for elements in the `txt` column that `isin` `in_period_multiple_names`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset = df[df['txt'].isin(in_period_multiple_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4625679, 440078)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.shape[0], len(in_period_multiple_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>name</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/scratch/groups/malgeehe/celebs/chicago_corenl...</td>\n",
       "      <td>George Mem</td>\n",
       "      <td>CD_20151209222115_00011_492423658.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/scratch/groups/malgeehe/celebs/chicago_corenl...</td>\n",
       "      <td>Timmy Eritt</td>\n",
       "      <td>CD_20151209222115_00011_492423658.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/scratch/groups/malgeehe/celebs/chicago_corenl...</td>\n",
       "      <td>Jack Blackburn</td>\n",
       "      <td>CD_20151209222115_00011_492423658.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/scratch/groups/malgeehe/celebs/chicago_corenl...</td>\n",
       "      <td>Mike Twin Sul</td>\n",
       "      <td>CD_20151209222115_00011_492423658.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/scratch/groups/malgeehe/celebs/chicago_corenl...</td>\n",
       "      <td>Joe Was Sure ``</td>\n",
       "      <td>CD_20151209222115_00011_492423658.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path             name  \\\n",
       "8   /scratch/groups/malgeehe/celebs/chicago_corenl...       George Mem   \n",
       "9   /scratch/groups/malgeehe/celebs/chicago_corenl...      Timmy Eritt   \n",
       "10  /scratch/groups/malgeehe/celebs/chicago_corenl...   Jack Blackburn   \n",
       "11  /scratch/groups/malgeehe/celebs/chicago_corenl...    Mike Twin Sul   \n",
       "12  /scratch/groups/malgeehe/celebs/chicago_corenl...  Joe Was Sure ``   \n",
       "\n",
       "                                      txt  \n",
       "8   CD_20151209222115_00011_492423658.txt  \n",
       "9   CD_20151209222115_00011_492423658.txt  \n",
       "10  CD_20151209222115_00011_492423658.txt  \n",
       "11  CD_20151209222115_00011_492423658.txt  \n",
       "12  CD_20151209222115_00011_492423658.txt  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in case below crashes\n",
    "subset.to_csv('/home/users/fredner/workspace/df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# counter of sets\n",
    "articles = subset['txt'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way faster if we sort the df and chop for specific rows in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_sort = subset.sort_values('txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = sub_sort.groupby('txt').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['txt', 'path', 'name'], dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = g['path'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 2, 19, 2, 2]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update a Counter to keep memory down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pairs(rows, min_ = 2):\n",
    "    START = 0\n",
    "    N = len(rows)\n",
    "    C = Counter()\n",
    "    \n",
    "    for i,row in enumerate(rows):\n",
    "        candidates = list(subset[START:START + row]['name'])\n",
    "        L = Counter([frozenset(x) for x in itertools.combinations(candidates, r = 2)])\n",
    "        START += row\n",
    "        \n",
    "        # update Counter\n",
    "        C += L\n",
    "        L = None\n",
    "        \n",
    "        # loop progress\n",
    "        pct = round(i/N, 2) * 100\n",
    "        if pct % 0.1 == 0:\n",
    "            print('\\r{}%'.format(pct), end = '')\n",
    "        \n",
    "    # optionally trash values < N at the end\n",
    "    if min_:\n",
    "        C = {x : C[x] for x in C if C[x] >= min_}\n",
    "        \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%310.0932824611664\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data = get_pairs(rows[:round(len(rows)*0.01)])\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, at that rate it would take ~9 hours to process everything, assuming nothing crashes.\n",
    "\n",
    "Could try setting start values and passing this to multiprocessing. Then just combine all of the resulting Counters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_groups(rows):\n",
    "    pct = 0.01 # what percentage of the data to process at a time?\n",
    "    start_idx = list(range(0, len(rows), round(len(rows) * pct)))\n",
    "    end_idx = start_idx.copy()[1:]\n",
    "    end_idx.append(len(rows))\n",
    "    start_sum = [sum(rows[:x]) for x in idx]\n",
    "    return list(zip(start_idx, end_idx, start_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = make_groups(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pairs_groups(group):\n",
    "    START_IDX = group[0]\n",
    "    END_IDX = group[1]\n",
    "    START_SUM = group[2]\n",
    "    C = Counter()\n",
    "    \n",
    "    for i,row in enumerate(rows[START_IDX:END_IDX]):\n",
    "        candidates = list(subset[START_SUM:START_SUM + row]['name'])\n",
    "        L = Counter([frozenset(x) for x in itertools.combinations(candidates, r = 2)])\n",
    "        START_SUM += row\n",
    "        \n",
    "        # update Counter\n",
    "        C += L\n",
    "        L = None\n",
    "    \n",
    "    print('group complete')\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n",
      "group complete\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with Pool() as p:\n",
    "    data = p.map(get_pairs_groups, groups)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is giving about a 4x speedup, which makes sense. So..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge results\n",
    "C = Counter()\n",
    "for x in data:\n",
    "    C += x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "786976"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(data, index = [0]).T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns = ['pair', 'co-occurrences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.sort_values('co-occurrences', ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And counting the pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_freqs = Counter(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop everything with freq < 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
